# Algorithm design
## Step 1: Conceptualization
This dataset is part of our Assignment 2: Algorithm Design (Project Work) for the Datalogical thinking course. It is a curated metadata collection derived from open source digital book https://www.kaggle.com/datasets/lokeshparab/gutenberg-books-and-metadata-2025.
### Team Members & Roles
| Name | Role | Contribution |
|------|------|---------------|
| **Muhammad Al-Waeli** | Data Research Lead | Dataset selection and initial setup |
| **Syeda Aisha Zaidi** | Problem & Algorithm Lead | Designed problem logic and algorithm |
| **Lilian Omolo** | Data Engineer | Cleaned and validated dataset; supported algorithm design |
| **Stefan Ionica** | Documentation Lead | Website setup, documentation, and Python code |
## Step 2: Curation of our Dataset
Dataset Overview
Column Name 
| Column Name | Description |
|--------------|-------------|
| **ID** | Unique identifier for each item in the dataset |
| **Type** | The kind of record (Text / Audio) |
| **Issued** | The year or date when the item was first published |
| **Title** | The title or name of the work |
| **Language** | The primary language of the work (e.g., English, French, German) |
| **Authors** | The creator(s) or main contributors of the work |
| **Subjects** | Thematic keywords or categories describing the content (e.g., Fiction, Science, History) |

#### Data Preparation Before Inclusion in the Repository

- The dataset was **cleaned and formatted** into a consistent CSV structure.  
- **Extra symbols, missing rows, and formatting errors** were removed.  
- All columns were checked to ensure **data consistency** (e.g., matching column headers and no blank identifiers).  
- Each record was validated to make sure the dataset met the **minimum requirement of 50+ entries**.
All records were validated to ensure at least **100 entries**, fulfilling assignment requirements.
**Intended Use:**
This dataset will be used to design and test an algorithmic model that processes bibliographic metadata.
**License & Usage:**
This dataset is intended for educational purposes only within the context of the Assignment 2 group project.
It is used under fair use for analysis, visualization, and algorithmic exploration.

## Step 3: Design Your Algorithm (Syeda Aisha Zaidi)

- Designing the **`CountPopularSubjects`** algorithm to analyze the dataset and identify the most frequent subject.  
- Writing **human-readable pseudocode** that meets the course requirements for iteration, selection, and variable use.  
- Providing detailed explanations for each algorithm step in the README.  
- Checking that the datasetâ€™s `Subjects` column was suitable for analysis.  
- Editing and organizing the project documentation in GitHub.

This contribution demonstrates my understanding of algorithmic design, structured data processing, and technical documentation using Markdown.


## Step 4: Website
The website was created following the steps below:  
- **Skeleton** creation.  
- Insertion of the body **content**  
- Building the general **structure**.
- **Attributes** team member information was included  
- Testing of final website to ensure interactivity
